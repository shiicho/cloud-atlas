# 06 - cgroups v2ï¼šèµ„æºé™åˆ¶å®æˆ˜

> **ç›®æ ‡**ï¼šæŒæ¡ cgroups v2 èµ„æºæ§åˆ¶å®æˆ˜ â€”â€” é…ç½® CPU/å†…å­˜/IO é™åˆ¶ï¼Œç†è§£ OOM Kill è°ƒæŸ¥  
> **å‰ç½®**ï¼š[Lesson 05 - cgroups v2 æ¶æ„](../05-cgroups-v2-architecture/)  
> **æ—¶é—´**ï¼šâš¡ 40 åˆ†é’Ÿï¼ˆé€Ÿè¯»ï¼‰/ ğŸ”¬ 150 åˆ†é’Ÿï¼ˆå®Œæ•´å®æ“ï¼‰  
> **ç¯å¢ƒ**ï¼šLinux ç³»ç»Ÿï¼ˆcgroup v2 enabledï¼Œå»ºè®® Ubuntu 22.04+ / RHEL 9+)  

---

## å°†å­¦åˆ°çš„å†…å®¹

1. æ‰‹åŠ¨åˆ›å»º cgroup å¹¶é…ç½®èµ„æºé™åˆ¶
2. ç†è§£ `memory.high` vs `memory.max` çš„å…³é”®åŒºåˆ«
3. è§‚å¯Ÿ CPU é™åˆ¶å’Œå†…å­˜ OOM Kill æ•ˆæœ
4. è°ƒæŸ¥ã€Œé™é»˜ OOM Killã€â€”â€” æ—¥æœ¬ IT è¿ç»´ç°åœºå¸¸è§çš„å¤œé—´æ‰¹å¤„ç†é—®é¢˜

---

## å…ˆè·‘èµ·æ¥ï¼š5 åˆ†é’Ÿè§¦å‘ OOM Kill

> **ä¸è®²åŸç†ï¼Œå…ˆåŠ¨æ‰‹ï¼** ä½ é©¬ä¸Šå°±ä¼šçœ‹åˆ° Linux å†…æ ¸æ€æ­»è¿›ç¨‹çš„ã€Œè¯æ®ã€ã€‚  

### å‡†å¤‡å·¥ä½œ

å®‰è£… stress å·¥å…·ï¼ˆå¦‚æœæ²¡æœ‰ï¼‰ï¼š

```bash
# Ubuntu/Debian
sudo apt-get install -y stress

# RHEL/CentOS
sudo dnf install -y stress
```

### åˆ›å»ºä¸€ä¸ªå†…å­˜å—é™çš„ cgroup

```bash
# åˆ›å»º cgroupï¼ˆéœ€è¦ root æƒé™ï¼‰
sudo mkdir /sys/fs/cgroup/demo-oom

# è®¾ç½®å†…å­˜ç¡¬é™åˆ¶ä¸º 50MB
echo "50M" | sudo tee /sys/fs/cgroup/demo-oom/memory.max

# æŠŠå½“å‰ shell åŠ å…¥è¿™ä¸ª cgroup
echo $$ | sudo tee /sys/fs/cgroup/demo-oom/cgroup.procs
```

### è§¦å‘ OOM Kill

```bash
# å°è¯•åˆ†é… 100MB å†…å­˜ï¼ˆè¶…è¿‡ 50MB é™åˆ¶ï¼‰
stress --vm 1 --vm-bytes 100M --timeout 10s
```

è¾“å‡ºï¼š

```
stress: info: [12345] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
stress: FAIL: [12345] (415) <-- worker 12346 got signal 9
stress: WARN: [12345] (417) now reaping child worker processes
stress: FAIL: [12345] (451) failed run completed in 0s
```

**Signal 9 å°±æ˜¯ SIGKILLï¼** å†…æ ¸æ€æ­»äº† stress è¿›ç¨‹ã€‚

### æŸ¥çœ‹ OOM è¯æ®

```bash
# æŸ¥çœ‹å†…æ ¸æ—¥å¿—
dmesg | tail -20 | grep -i oom
```

è¾“å‡ºç±»ä¼¼ï¼š

```
[12345.678901] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=...
[12345.678902] Memory cgroup out of memory: Killed process 12346 (stress)
```

```bash
# æŸ¥çœ‹ cgroup çš„ OOM äº‹ä»¶ç»Ÿè®¡
cat /sys/fs/cgroup/demo-oom/memory.events
```

è¾“å‡ºï¼š

```
low 0
high 0
max 1
oom 1
oom_kill 1
oom_group_kill 0
```

**oom_kill 1** â€”â€” è®°å½•äº†ä¸€æ¬¡ OOM Kill äº‹ä»¶ï¼

### æ¸…ç†

```bash
# é€€å‡º cgroupï¼ˆæ–°å¼€ä¸€ä¸ª shellï¼‰
# æˆ–è€…åˆ é™¤ cgroup
sudo rmdir /sys/fs/cgroup/demo-oom
```

---

**ä½ åˆšåˆšåšäº†ä»€ä¹ˆï¼Ÿ**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      cgroup: demo-oom                           â”‚
â”‚                      memory.max = 50MB                          â”‚
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  stress --vm-bytes 100M                                 â”‚   â”‚
â”‚   â”‚                                                         â”‚   â”‚
â”‚   â”‚  å°è¯•åˆ†é… 100MB                                         â”‚   â”‚
â”‚   â”‚       â”‚                                                 â”‚   â”‚
â”‚   â”‚       â–¼                                                 â”‚   â”‚
â”‚   â”‚  è¶…è¿‡ memory.max é™åˆ¶                                   â”‚   â”‚
â”‚   â”‚       â”‚                                                 â”‚   â”‚
â”‚   â”‚       â–¼                                                 â”‚   â”‚
â”‚   â”‚  å†…æ ¸è§¦å‘ OOM Kill                                      â”‚   â”‚
â”‚   â”‚       â”‚                                                 â”‚   â”‚
â”‚   â”‚       â–¼                                                 â”‚   â”‚
â”‚   â”‚  è¿›ç¨‹æ”¶åˆ° SIGKILL (Signal 9)                            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â”‚   è¯æ®è®°å½•ï¼š                                                    â”‚
â”‚   - dmesg: "Memory cgroup out of memory"                       â”‚
â”‚   - memory.events: oom_kill 1                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

è¿™å°±æ˜¯å®¹å™¨èµ„æºé™åˆ¶çš„æ ¸å¿ƒæœºåˆ¶ã€‚Docker/Kubernetes çš„ `--memory` å‚æ•°èƒŒåå°±æ˜¯è¿™ä¸ª cgroup é…ç½®ã€‚

---

## å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ

### cgroup èµ„æºæ§åˆ¶æ–‡ä»¶

å½“ä½ åˆ›å»º `/sys/fs/cgroup/demo-oom` ç›®å½•æ—¶ï¼Œå†…æ ¸è‡ªåŠ¨ç”Ÿæˆäº†ä¸€ç³»åˆ—æ§åˆ¶æ–‡ä»¶ï¼š

```bash
ls /sys/fs/cgroup/demo-oom/
```

```
cgroup.controllers  cpu.max      memory.current  memory.max   pids.max
cgroup.procs        cpu.stat     memory.events   memory.stat  ...
```

å…³é”®æ–‡ä»¶ï¼š

| æ–‡ä»¶ | ä½œç”¨ | ç¤ºä¾‹å€¼ |
|------|------|--------|
| `memory.max` | å†…å­˜ç¡¬é™åˆ¶ | `50M`, `1G`, `max`(æ— é™åˆ¶) |
| `memory.high` | å†…å­˜è½¯é™åˆ¶ | `40M` |
| `memory.current` | å½“å‰å†…å­˜ä½¿ç”¨ | `12345678`(å­—èŠ‚) |
| `memory.events` | OOM äº‹ä»¶ç»Ÿè®¡ | `oom_kill 1` |
| `cpu.max` | CPU æ—¶é—´é™åˆ¶ | `50000 100000`(50%) |
| `pids.max` | æœ€å¤§è¿›ç¨‹æ•° | `100` |

### è¿›ç¨‹å¦‚ä½•è¢«é™åˆ¶

```bash
echo $$ | sudo tee /sys/fs/cgroup/demo-oom/cgroup.procs
```

è¿™ä¸€è¡Œåšäº†ä»€ä¹ˆï¼Ÿ

1. `$$` æ˜¯å½“å‰ shell çš„ PID
2. å†™å…¥ `cgroup.procs` å°†è¿›ç¨‹ç§»å…¥è¯¥ cgroup
3. è¯¥è¿›ç¨‹åŠå…¶**æ‰€æœ‰å­è¿›ç¨‹**éƒ½å—è¯¥ cgroup é™åˆ¶

---

## æ ¸å¿ƒæ¦‚å¿µï¼šmemory.high vs memory.max

**è¿™æ˜¯ cgroups v2 æœ€é‡è¦çš„æ¦‚å¿µä¹‹ä¸€ï¼Œä¹Ÿæ˜¯è¿ç»´é¢è¯•å¸¸è€ƒé¢˜ã€‚**

### ä¸¤ç§å†…å­˜é™åˆ¶

```
                    å†…å­˜ä½¿ç”¨é‡
                        â”‚
    0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶
                        â”‚
                        â”‚  æ­£å¸¸è¿è¡Œ
                        â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€ memory.high (è½¯é™åˆ¶)
                        â”‚
                        â”‚  ç³»ç»Ÿç§¯æå›æ”¶å†…å­˜
                        â”‚  è¿›ç¨‹å˜æ…¢ä½†ç»§ç»­è¿è¡Œ
                        â”‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€ memory.max (ç¡¬é™åˆ¶)
                        â”‚
                        â”‚  è§¦å‘ OOM Kill
                        â”‚  è¿›ç¨‹è¢«æ€æ­»
                        â”‚
```

### è¯¦ç»†å¯¹æ¯”

| ç‰¹æ€§ | memory.high (è½¯é™åˆ¶) | memory.max (ç¡¬é™åˆ¶) |
|------|----------------------|---------------------|
| **è§¦å‘æ¡ä»¶** | ä½¿ç”¨é‡è¶…è¿‡ high | ä½¿ç”¨é‡è¾¾åˆ° max |
| **ç³»ç»Ÿè¡Œä¸º** | ç§¯æå›æ”¶å†…å­˜ï¼ˆmemory reclaimï¼‰ | è§¦å‘ OOM Kill |
| **è¿›ç¨‹çŠ¶æ€** | å˜æ…¢ä½†ç»§ç»­è¿è¡Œ | è¢«æ€æ­» |
| **ç”¨é€”** | é¿å…çªç„¶ OOM | ç»å¯¹ä¸Šé™ |
| **æ¨èå€¼** | ç›®æ ‡çš„ 80% | ç›®æ ‡å€¼ |

### æ¨èé…ç½®æ¨¡å¼

```bash
# ç›®æ ‡ï¼šé™åˆ¶è¿›ç¨‹æœ€å¤šä½¿ç”¨ 1GB å†…å­˜
# é…ç½® high ä¸º 800Mï¼Œmax ä¸º 1G

echo "800M" | sudo tee /sys/fs/cgroup/myapp/memory.high   # è½¯é™åˆ¶
echo "1G"   | sudo tee /sys/fs/cgroup/myapp/memory.max    # ç¡¬é™åˆ¶
```

è¿™æ ·é…ç½®çš„æ•ˆæœï¼š

- ä½¿ç”¨é‡ < 800Mï¼šæ­£å¸¸è¿è¡Œ
- 800M < ä½¿ç”¨é‡ < 1Gï¼šç³»ç»Ÿç§¯æå›æ”¶å†…å­˜ï¼Œè¿›ç¨‹å˜æ…¢ä½†ä¸ä¼šæ­»
- ä½¿ç”¨é‡ = 1Gï¼šOOM Kill

**ä¸ºä»€ä¹ˆéœ€è¦ memory.highï¼Ÿ**

å¦‚æœåªè®¾ç½® memory.maxï¼Œè¿›ç¨‹ä¼šã€Œçªç„¶æ­»äº¡ã€ï¼Œæ²¡æœ‰é¢„è­¦ã€‚è®¾ç½® memory.high ç»™ç³»ç»Ÿä¸€ä¸ªã€Œç¼“å†²åŒºã€ï¼Œè®©è¿›ç¨‹æœ‰æœºä¼šé‡Šæ”¾å†…å­˜æˆ–è¢«ç›‘æ§å‘ç°ã€‚

---

## åŠ¨æ‰‹ç»ƒä¹ 

### Lab 1ï¼šæ‰‹åŠ¨åˆ›å»º cgroup å¹¶é…ç½®èµ„æºé™åˆ¶

**ç›®æ ‡**ï¼šç†è§£ cgroup åˆ›å»ºå’Œèµ„æºé™åˆ¶é…ç½®

**æ­¥éª¤ 1**ï¼šåˆ›å»º cgroup

```bash
# åˆ›å»º cgroup ç›®å½•
sudo mkdir /sys/fs/cgroup/lab-resource

# æŸ¥çœ‹å¯ç”¨æ§åˆ¶å™¨
cat /sys/fs/cgroup/cgroup.controllers

# æŸ¥çœ‹å½“å‰ cgroup å·²å¯ç”¨çš„æ§åˆ¶å™¨
cat /sys/fs/cgroup/cgroup.subtree_control
```

**æ­¥éª¤ 2**ï¼šé…ç½®å†…å­˜é™åˆ¶

```bash
# è®¾ç½®è½¯é™åˆ¶å’Œç¡¬é™åˆ¶
echo "80M" | sudo tee /sys/fs/cgroup/lab-resource/memory.high
echo "100M" | sudo tee /sys/fs/cgroup/lab-resource/memory.max

# éªŒè¯é…ç½®
cat /sys/fs/cgroup/lab-resource/memory.high
cat /sys/fs/cgroup/lab-resource/memory.max
```

**æ­¥éª¤ 3**ï¼šé…ç½® CPU é™åˆ¶ï¼ˆ50%ï¼‰

```bash
# cpu.max æ ¼å¼ï¼š'quota period'
# '50000 100000' è¡¨ç¤ºæ¯ 100ms åªèƒ½ä½¿ç”¨ 50ms CPU
echo "50000 100000" | sudo tee /sys/fs/cgroup/lab-resource/cpu.max

# éªŒè¯
cat /sys/fs/cgroup/lab-resource/cpu.max
```

**æ­¥éª¤ 4**ï¼šé…ç½® PID é™åˆ¶

```bash
# é™åˆ¶æœ€å¤š 10 ä¸ªè¿›ç¨‹
echo "10" | sudo tee /sys/fs/cgroup/lab-resource/pids.max

# éªŒè¯
cat /sys/fs/cgroup/lab-resource/pids.max
```

**æ¸…ç†**ï¼š

```bash
sudo rmdir /sys/fs/cgroup/lab-resource
```

---

### Lab 2ï¼šå†…å­˜é™åˆ¶ + OOM æ¼”ç¤º

**ç›®æ ‡**ï¼šè§‚å¯Ÿ memory.high å’Œ memory.max çš„ä¸åŒè¡Œä¸º

è¿è¡Œæ¼”ç¤ºè„šæœ¬ï¼š

```bash
cd ~/cloud-atlas/foundations/linux/lx11-containers/06-cgroups-v2-resource-control/code
sudo ./memory-limit-demo.sh
```

æˆ–æ‰‹åŠ¨æ‰§è¡Œï¼š

**æ¼”ç¤º memory.highï¼ˆè½¯é™åˆ¶ï¼‰**ï¼š

```bash
# åˆ›å»º cgroup
sudo mkdir /sys/fs/cgroup/demo-high

# åªè®¾ç½® memory.highï¼ˆè½¯é™åˆ¶ï¼‰ï¼Œä¸è®¾ç½® memory.max
echo "50M" | sudo tee /sys/fs/cgroup/demo-high/memory.high

# å¯åŠ¨æ–° shell åœ¨è¿™ä¸ª cgroup ä¸­
sudo bash -c 'echo $$ > /sys/fs/cgroup/demo-high/cgroup.procs && exec bash'

# åœ¨æ–° shell ä¸­ï¼Œå°è¯•åˆ†é… 80M å†…å­˜
stress --vm 1 --vm-bytes 80M --timeout 5s

# è§‚å¯Ÿè¿›ç¨‹å˜æ…¢ä½†æ²¡æœ‰è¢«æ€æ­»
# æŸ¥çœ‹äº‹ä»¶
cat /sys/fs/cgroup/demo-high/memory.events
```

**æ¼”ç¤º memory.maxï¼ˆç¡¬é™åˆ¶ï¼‰**ï¼š

```bash
# åˆ›å»º cgroup
sudo mkdir /sys/fs/cgroup/demo-max

# è®¾ç½® memory.maxï¼ˆç¡¬é™åˆ¶ï¼‰
echo "50M" | sudo tee /sys/fs/cgroup/demo-max/memory.max

# å¯åŠ¨æ–° shell
sudo bash -c 'echo $$ > /sys/fs/cgroup/demo-max/cgroup.procs && exec bash'

# å°è¯•åˆ†é… 80M å†…å­˜
stress --vm 1 --vm-bytes 80M --timeout 5s

# è§‚å¯Ÿè¿›ç¨‹è¢«æ€æ­»
cat /sys/fs/cgroup/demo-max/memory.events
```

**æ¸…ç†**ï¼š

```bash
sudo rmdir /sys/fs/cgroup/demo-high 2>/dev/null
sudo rmdir /sys/fs/cgroup/demo-max 2>/dev/null
```

---

### Lab 3ï¼šCPU é™åˆ¶æ¼”ç¤º

**ç›®æ ‡**ï¼šè§‚å¯Ÿ CPU æ—¶é—´è¢«é™åˆ¶åœ¨ 50%

è¿è¡Œæ¼”ç¤ºè„šæœ¬ï¼š

```bash
cd ~/cloud-atlas/foundations/linux/lx11-containers/06-cgroups-v2-resource-control/code
sudo ./cpu-throttle-demo.sh
```

æˆ–æ‰‹åŠ¨æ‰§è¡Œï¼š

**æ­¥éª¤ 1**ï¼šåˆ›å»º CPU é™åˆ¶ cgroup

```bash
sudo mkdir /sys/fs/cgroup/demo-cpu

# é™åˆ¶ä¸º 50% CPU
# '50000 100000' = æ¯ 100000 å¾®ç§’åªèƒ½ç”¨ 50000 å¾®ç§’
echo "50000 100000" | sudo tee /sys/fs/cgroup/demo-cpu/cpu.max
```

**æ­¥éª¤ 2**ï¼šè¿è¡Œ CPU å¯†é›†ä»»åŠ¡

```bash
# åœ¨ä¸€ä¸ªç»ˆç«¯å¯åŠ¨ stressï¼ˆä¸åœ¨ cgroup ä¸­ï¼‰
stress --cpu 1 --timeout 30s &
STRESS_PID=$!

# æŸ¥çœ‹ CPU ä½¿ç”¨ç‡ï¼ˆåº”è¯¥æ¥è¿‘ 100%ï¼‰
top -p $STRESS_PID -b -n 1 | tail -2

# æ€æ‰
kill $STRESS_PID
```

**æ­¥éª¤ 3**ï¼šåœ¨ cgroup ä¸­è¿è¡ŒåŒæ ·ä»»åŠ¡

```bash
# å°†è¿›ç¨‹åŠ å…¥ cgroup è¿è¡Œ
sudo bash -c "echo \$\$ > /sys/fs/cgroup/demo-cpu/cgroup.procs && stress --cpu 1 --timeout 30s" &
STRESS_PID=$!

# æŸ¥çœ‹ CPU ä½¿ç”¨ç‡ï¼ˆåº”è¯¥é™åˆ¶åœ¨ 50% å·¦å³ï¼‰
sleep 2
top -p $STRESS_PID -b -n 1 | tail -2

# ç­‰å¾…å®Œæˆæˆ–æ€æ‰
kill $STRESS_PID 2>/dev/null
```

**æ­¥éª¤ 4**ï¼šæŸ¥çœ‹ CPU ç»Ÿè®¡

```bash
cat /sys/fs/cgroup/demo-cpu/cpu.stat
```

è¾“å‡ºï¼š

```
usage_usec 12345678       # æ€» CPU ä½¿ç”¨æ—¶é—´
user_usec 12000000        # ç”¨æˆ·æ€æ—¶é—´
system_usec 345678        # å†…æ ¸æ€æ—¶é—´
nr_periods 1234           # è°ƒåº¦å‘¨æœŸæ•°
nr_throttled 567          # è¢«é™åˆ¶çš„å‘¨æœŸæ•°
throttled_usec 8901234    # è¢«é™åˆ¶çš„æ€»æ—¶é—´
```

**nr_throttled** > 0 è¡¨ç¤º CPU é™åˆ¶ç”Ÿæ•ˆäº†ï¼

**æ¸…ç†**ï¼š

```bash
sudo rmdir /sys/fs/cgroup/demo-cpu
```

---

### Lab 4ï¼šSilent OOM åœºæ™¯è°ƒæŸ¥

**åœºæ™¯**ï¼šå¤œé—´æ‰¹å¤„ç†å‡Œæ™¨ 3 ç‚¹çªç„¶æ¶ˆå¤±ï¼Œæ²¡æœ‰ä»»ä½•åº”ç”¨æ—¥å¿—

è¿™æ˜¯æ—¥æœ¬ IT è¿ç»´ç°åœºçš„ç»å…¸é—®é¢˜ã€‚æ‰¹å¤„ç†ç¨‹åºï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰åœ¨å‡Œæ™¨è¿è¡Œï¼Œæ—©ä¸Šå‘ç°å®ƒã€Œæ¶ˆå¤±ã€äº†ï¼Œä½†æ²¡æœ‰é”™è¯¯æ—¥å¿—ã€‚

**ç›®æ ‡**ï¼šå­¦ä¼šä»å®¿ä¸»æœºè§†è§’è°ƒæŸ¥å®¹å™¨/è¿›ç¨‹é—®é¢˜

**æ¨¡æ‹Ÿåœºæ™¯**ï¼š

```bash
# æ­¥éª¤ 1ï¼šåˆ›å»ºå—é™ cgroup æ¨¡æ‹Ÿå®¹å™¨
sudo mkdir /sys/fs/cgroup/batch-job

# æ­¥éª¤ 2ï¼šè®¾ç½®å†…å­˜é™åˆ¶ï¼ˆæ¨¡æ‹Ÿ Kubernetes pod é™åˆ¶ï¼‰
echo "100M" | sudo tee /sys/fs/cgroup/batch-job/memory.max

# æ­¥éª¤ 3ï¼šè¿è¡Œã€Œæ‰¹å¤„ç†ã€ä»»åŠ¡ï¼ˆä¼šè¢« OOM Killï¼‰
sudo bash -c 'echo $$ > /sys/fs/cgroup/batch-job/cgroup.procs && stress --vm 1 --vm-bytes 200M --timeout 60s'
```

è¿›ç¨‹ä¼šç«‹å³è¢«æ€æ­»ã€‚

**è°ƒæŸ¥æ­¥éª¤**ï¼š

```bash
# è¯æ® 1ï¼šæ£€æŸ¥ dmesgï¼ˆå†…æ ¸æ—¥å¿—ï¼‰
dmesg | grep -i oom | tail -10
```

è¾“å‡ºï¼š

```
[xxxxx.xxxxxx] oom-kill:constraint=CONSTRAINT_MEMCG...
[xxxxx.xxxxxx] Memory cgroup out of memory: Killed process XXXX (stress)
[xxxxx.xxxxxx] oom_reaper: reaped process XXXX (stress)
```

```bash
# è¯æ® 2ï¼šæ£€æŸ¥ memory.events
cat /sys/fs/cgroup/batch-job/memory.events
```

è¾“å‡ºï¼š

```
low 0
high 0
max 1
oom 1
oom_kill 1
```

```bash
# è¯æ® 3ï¼šä½¿ç”¨ journalctl æŸ¥çœ‹å†…æ ¸æ¶ˆæ¯
journalctl -k | grep -i oom | tail -10
```

**ç”Ÿæˆéšœå®³å ±å‘Šæ›¸ï¼ˆäº‹æ•…æŠ¥å‘Šï¼‰**ï¼š

```markdown
## éšœå®³å ±å‘Šæ›¸

### äº‹è±¡
å¤œé–“ãƒãƒƒãƒå‡¦ç†ãŒ 03:00 ã«ç•°å¸¸çµ‚äº†ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã«è¨˜éŒ²ãªã—ã€‚

### åŸå› 
cgroup ãƒ¡ãƒ¢ãƒªåˆ¶é™ã«ã‚ˆã‚‹ OOM Kill

### è¨¼æ‹ 
1. dmesg å‡ºåŠ›ï¼š
   `Memory cgroup out of memory: Killed process XXXX (stress)`

2. memory.eventsï¼š
   `oom_kill 1`

### å¯¾ç­–
- ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’ 200M ã«å¼•ãä¸Šã’
- ã¾ãŸã¯ memory.high ã‚’è¨­å®šã—ã¦äº‹å‰è­¦å‘Šã‚’æœ‰åŠ¹åŒ–
```

**æ¸…ç†**ï¼š

```bash
sudo rmdir /sys/fs/cgroup/batch-job
```

---

## IO æ§åˆ¶ï¼ˆç®€ä»‹ï¼‰

cgroups v2 ä¹Ÿæ”¯æŒ IO é™åˆ¶ï¼Œä½†é…ç½®ç¨å¤æ‚ã€‚

### æŸ¥çœ‹è®¾å¤‡å·

```bash
# æŸ¥çœ‹ç£ç›˜è®¾å¤‡çš„ major:minor å·
lsblk -d -o NAME,MAJ:MIN
```

è¾“å‡ºï¼š

```
NAME MAJ:MIN
sda    8:0
nvme0n1 259:0
```

### é…ç½® IO é™åˆ¶

```bash
# åˆ›å»º cgroup
sudo mkdir /sys/fs/cgroup/demo-io

# é™åˆ¶å¯¹ sda (8:0) çš„è¯»å†™å¸¦å®½ä¸º 10MB/s
echo "8:0 rbps=10485760 wbps=10485760" | sudo tee /sys/fs/cgroup/demo-io/io.max

# éªŒè¯
cat /sys/fs/cgroup/demo-io/io.max
```

æ ¼å¼è¯´æ˜ï¼š

```
MAJ:MIN rbps=è¯»å¸¦å®½(bytes/s) wbps=å†™å¸¦å®½(bytes/s) riops=è¯»IOPS wiops=å†™IOPS
```

**æ³¨æ„**ï¼šIO æ§åˆ¶æ•ˆæœå–å†³äºåº•å±‚å­˜å‚¨ç±»å‹ï¼ŒSSD/NVMe çš„æ•ˆæœå¯èƒ½ä¸å¦‚ HDD æ˜æ˜¾ã€‚

---

## PID æ§åˆ¶ï¼ˆé˜²æ­¢ Fork ç‚¸å¼¹ï¼‰

### é—®é¢˜åœºæ™¯

```bash
# ä¸è¦è¿è¡Œè¿™ä¸ªï¼è¿™æ˜¯ fork bomb
# :(){ :|:& };:
```

Fork ç‚¸å¼¹ä¼šæ— é™åˆ›å»ºè¿›ç¨‹ï¼Œè€—å°½ç³»ç»Ÿèµ„æºã€‚

### è§£å†³æ–¹æ¡ˆï¼špids.max

```bash
# åˆ›å»º cgroup
sudo mkdir /sys/fs/cgroup/demo-pids

# é™åˆ¶æœ€å¤š 5 ä¸ªè¿›ç¨‹
echo "5" | sudo tee /sys/fs/cgroup/demo-pids/pids.max

# æµ‹è¯•
sudo bash -c 'echo $$ > /sys/fs/cgroup/demo-pids/cgroup.procs && for i in {1..10}; do sleep 100 & done'
```

è¾“å‡ºï¼š

```
-bash: fork: retry: Resource temporarily unavailable
-bash: fork: retry: Resource temporarily unavailable
```

åªæœ‰å‰ 5 ä¸ªè¿›ç¨‹èƒ½åˆ›å»ºæˆåŠŸï¼

**æ¸…ç†**ï¼š

```bash
# å…ˆæ€æ­» sleep è¿›ç¨‹
sudo pkill -9 -f "sleep 100"
sudo rmdir /sys/fs/cgroup/demo-pids
```

---

## èŒåœºå°è´´å£«

### æ—¥æœ¬ IT ç°åœºå¸¸è§åœºæ™¯

**åœºæ™¯ 1ï¼šOOM Kill ã¯å¤œé–“ãƒãƒƒãƒå•é¡Œã®ä¸»åŸå› **

```
çŠ¶æ³ï¼š
æœå‡ºç¤¾ã™ã‚‹ã¨ã€å¤œé–“ãƒãƒƒãƒãŒå¤±æ•—ã—ã¦ã„ãŸã€‚
ã‚¢ãƒ—ãƒªãƒ­ã‚°ã«ã¯ä½•ã‚‚è¨˜éŒ²ã•ã‚Œã¦ã„ãªã„ã€‚

ç¢ºèªæ‰‹é †ï¼š
1. dmesg | grep -i oom
2. cat /sys/fs/cgroup/<container>/memory.events
3. journalctl -k | grep -i oom

å ±å‘Šæ›¸ã«æ·»ä»˜ï¼š
- dmesg ã®å‡ºåŠ›
- memory.events ã®å†…å®¹
- æ¨å¥¨å¯¾ç­–ï¼ˆãƒ¡ãƒ¢ãƒªå¢—åŠ  or memory.high è¨­å®šï¼‰
```

**åœºæ™¯ 2ï¼šKubernetes Pod OOM èª¿æŸ»**

```bash
# Pod ãŒ CrashLoopBackOff ã«ãªã£ã¦ã„ã‚‹
kubectl describe pod <pod-name>

# Events ã« OOMKilled ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å ´åˆ
# ãƒãƒ¼ãƒ‰ã§ç¢ºèªï¼š
ssh <node>
dmesg | grep -i oom | grep <container-id>
```

**åœºæ™¯ 3ï¼šãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ã®è¨­å®šç¢ºèª**

```bash
# Docker ã‚³ãƒ³ãƒ†ãƒŠã®ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ã‚’ç¢ºèª
docker inspect <container> | jq '.[0].HostConfig.Memory'
docker inspect <container> | jq '.[0].HostConfig.CpuQuota'

# cgroup ã§ç›´æ¥ç¢ºèª
cat /sys/fs/cgroup/system.slice/docker-<id>.scope/memory.max
cat /sys/fs/cgroup/system.slice/docker-<id>.scope/cpu.max
```

### é‹ç”¨ç›£è¦–ã®ãƒã‚¤ãƒ³ãƒˆ

1. **memory.events ã‚’å®šæœŸç›£è¦–**
   - oom_kill > 0 ã®å ´åˆã¯ã‚¢ãƒ©ãƒ¼ãƒˆ
   - high ã‚¤ãƒ™ãƒ³ãƒˆãŒå¤šã„å ´åˆã¯ memory.high ã«è¿‘ã¥ã„ã¦ã„ã‚‹

2. **cpu.stat ã® nr_throttled ã‚’ç›£è¦–**
   - å€¤ãŒå¢—ãˆç¶šã‘ã‚‹å ´åˆã¯ CPU åˆ¶é™ã«å¼•ã£ã‹ã‹ã£ã¦ã„ã‚‹

3. **pids.current ã‚’ç›£è¦–**
   - pids.max ã«è¿‘ã¥ã„ã¦ã„ã‚‹å ´åˆã¯ fork åˆ¶é™ã«æ³¨æ„

---

## æ£€æŸ¥æ¸…å•

å®Œæˆæœ¬è¯¾åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

- [ ] æ‰‹åŠ¨åˆ›å»º cgroup ç›®å½• (`mkdir /sys/fs/cgroup/xxx`)
- [ ] é…ç½®å†…å­˜é™åˆ¶ (`memory.high`, `memory.max`)
- [ ] é…ç½® CPU é™åˆ¶ (`cpu.max = 'quota period'`)
- [ ] é…ç½® PID é™åˆ¶ (`pids.max`)
- [ ] è§£é‡Š `memory.high` å’Œ `memory.max` çš„åŒºåˆ«
- [ ] ä½¿ç”¨ `stress` è§¦å‘ OOM Kill å¹¶è§‚å¯Ÿç°è±¡
- [ ] ä» `dmesg` å’Œ `memory.events` æ‰¾åˆ° OOM Kill è¯æ®
- [ ] ç†è§£æ—¥æœ¬ IT ç°åœºçš„å¤œé—´æ‰¹å¤„ç† OOM é—®é¢˜

---

## å»¶ä¼¸é˜…è¯»

### å®˜æ–¹æ–‡æ¡£

- [cgroups v2 - Kernel Documentation](https://www.kernel.org/doc/Documentation/cgroup-v2.txt)
- [Memory Controller - cgroups v2](https://docs.kernel.org/admin-guide/cgroup-v2.html#memory)
- [CPU Controller - cgroups v2](https://docs.kernel.org/admin-guide/cgroup-v2.html#cpu)

### ç›¸å…³è¯¾ç¨‹

- [Lesson 05 - cgroups v2 æ¶æ„](../05-cgroups-v2-architecture/) - cgroups v2 ç»Ÿä¸€å±‚çº§åŸç†
- [Lesson 11 - å®¹å™¨æ•…éšœæ’æŸ¥](../11-debugging-troubleshooting/) - å®Œæ•´æ’æŸ¥æ–¹æ³•è®º
- [LX05 - systemd èµ„æºæ§åˆ¶](../../lx05-systemd/) - systemd ä¸ cgroups é›†æˆ

### æ¨èé˜…è¯»

- *Container Security* by Liz Rice - Chapter on cgroups
- Red Hat Documentation: Resource Management Guide

---

## ç³»åˆ—å¯¼èˆª

[<-- 05 - cgroups v2 æ¶æ„](../05-cgroups-v2-architecture/) | [Home](../) | [07 - OverlayFS -->](../07-overlay-filesystems/)
